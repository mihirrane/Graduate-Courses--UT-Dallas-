---
title: "Mini Project - 6"
output: 
  html_document:
    keep_md: true
---

## R Markdown

**Q.1- Consider the prostate cancer dataset available on eLearning as prostate cancer.csv. It consists of data on 97 men with advanced prostate cancer. A description of the variables is given in Figure 1. We would like to understand how PSA level is related to the other predictors in the dataset. Note that vesinv is a qualitative variable. You can treat gleason as a quantitative variable. Build a “reasonably good” linear model for these data by taking PSA level as the response variable. Carefully justify all the choices you make in building the model. Be sure to verify the model assumptions. In case a transformation of response is necessary, try the natural log transformation. Use the ﬁnal model to predict the PSA level for a patient whose quantitative predictors are at the sample means of the variables and qualitative predictors are at the most frequent category.**

```{r}
#Dataset imported and stored in data        
cancer_data <- read.csv("data/prostate_cancer.csv",header = T, sep = ',')

# side by side plots
par(mfrow=c(1,2))
boxplot(cancer_data$psa, main = "Boxplot of PSA")
qqnorm(cancer_data$psa)
qqline(cancer_data$psa)

```

My observation :
The boxplot seems to have a lot of outliers and the points on the qqplot do not fit the qqline this implies the data is not normal.  
We use logarithmic transformation of these values for better fit.
Now drawing the boxplot and qqplot for log(psa), we get 


```{r}
# side by side plots
par(mfrow=c(1,2))
boxplot(log(cancer_data$psa), main = "Boxplot of log(PSA)")
qqnorm(log(cancer_data$psa))
line(log(cancer_data$psa))
```

My observation :
We see now that the boxplot seem to have less outliers than before and also seems symmetrical. And the qqplot appears to be normal. 
 
Now we draw the scatterplots of each and every predictor against the y, so as to find on which predictors y seems to depend on  

```{r}
#Lmplot to plot a linear model of heart rate vs body temperature
 par(mfrow = c(2,4))
 y <- log(cancer_data$psa)
 plot(cancer_data$cancervol,y)
 fit1 <- lm(y ~ cancervol, data = cancer_data)
 abline(fit1)
 plot(cancer_data$weight, y)
 fit2 <- lm(y ~ weight, data = cancer_data)
 abline(fit2)
 plot(cancer_data$age, y)
 fit3 <- lm(y ~ age, data = cancer_data)
 abline(fit3)
 plot(cancer_data$benpros, y)
 fit4 <- lm(y ~ benpros, data = cancer_data)
 abline(fit4)
 plot(cancer_data$vesinv, y)
 fit5 <- lm(y ~ vesinv, data = cancer_data)
 abline(fit5)
 plot(cancer_data$capspen, y)
 fit6 <- lm(y ~ capspen, data = cancer_data) 
 abline(fit6)
 plot(cancer_data$gleason, y)
 fit7 <- lm(y ~ gleason, data = cancer_data)
 abline(fit7)

```


```{r}
library(GGally)
ggpairs(data=cancer_data, columns=c(1:9), title="PSA vs all predictors")
```
As we can see from the above correlation plot that cancervol, benpros, gleason and vesinv (treated as a categorical variable) are highly correlated to PSA.

We use automated techniques in R to get the models best suited for the given data. The function we use for that is step.
 
Doing the forward stepwise search we end up with a linear model which includes the predictors – cancervol, benpros, gleason and vesinv (treated as a categorical variable). 

```{r}
# automated techniques for models
 fit8.forward <- step(lm(y ~ 1, data = cancer_data), scope = list(upper = ~ cancervol + weight + age + benpros + as.factor(vesinv) + capspen + gleason), direction = "forward")
```

Now using the automated techniques, the downfall is that we may get over fitted models which fit the data at hand perfectly but are not so good at predicting the future values.  
 
Hence we try to verify the model by eliminating few of the predictors.

We do so by generating models which have one less model than the model generated by the automated methods and then use the anova function which compare analysis of variances for one or more fitted models.  

```{r}
# using anova to verify whether to kick out few indicators in the assumption that forward
 # stepwise fit gave an overfitted model
 fit9 <- lm(y ~ gleason + benpros + as.factor(vesinv), data = cancer_data)
 anova(fit9, fit8.forward)
 
  fit10 <- lm(y ~ cancervol + benpros + as.factor(vesinv), data = cancer_data)
 anova(fit10, fit8.forward)
 
  fit11 <- lm(y ~ cancervol + gleason + as.factor(vesinv), data = cancer_data)
 anova(fit11, fit8.forward)
 
 fit12 <- lm(y ~ cancervol + gleason + benpros, data = cancer_data)
 anova(fit12, fit8.forward)
 
```

Using Anova, results we found that the best model that fits the given data has the indicators cancervol, benpros, gleason and vesinv 

```{r}
# Summary for the fitted model
 summary(fit8.forward)
```

The p-value is greater than 0.05 and the F-statistic is large which is in favour of null hypothesis. There is not sufficient evidence to rule out this model.

Now to verify the model quality we check the residual plot for the given model

Drawing the scatter plot, qqplot and time series plots of the residuals we get:

```{r}
# Drawing scatter plot, qqplot and time series plot for residuals
 par(mfrow=c(1,1))
 plot(fitted(fit8.forward), resid(fit8.forward), main="Scatter Plot of Residuals")
 abline(h = 0)
 qqnorm(resid(fit8.forward))
 qqline(resid(fit8.forward))
```

We observe that the residuals are scattered throughout and the points fit the qq line very well. This implies "goodness of fit".

```{r}
plot(resid(fit8.forward), type = 'l', main = "Time Series Plot for Residuals")
 abline(h=0)
```

The above three graphs show that the error quantities have zero mean, constant variance, are normally distributed and are independent.

```{r}
# Predicting new value using the regression equation at the sample means of indicators
  prediction = fit8.forward$coefficients["(Intercept)"] +
(fit8.forward$coefficients["cancervol"]*mean(cancer_data$cancervol)) +
(fit8.forward$coefficients["benpros"]*mean(cancer_data$benpros)) +
(fit8.forward$coefficients["as.factor(vesinv)1"]*unique(cancer_data$vesinv)[which.max(tabulate(match(cancer_data$vesinv, unique(cancer_data$vesinv))))]) +
(fit8.forward$coefficients["gleason"]*mean(cancer_data$gleason))
 prediction
```

Predicted output is  2.330541
However as we had taken the log transformation earlier for the psa values, the value we have predicted is the log of the needed value. So computing antilog of the value, we get our actual predicted value which is 10.2835